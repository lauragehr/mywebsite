---
categories:  
- ""    #the front matter should be like the one found in, e.g., blog2.md. It cannot be like the normal Rmd we used
- ""
date: "2021-09-30"
description: Laura's pre-coure assignment # the title that will show up once someone gets to this page
draft: false
image: bubbles.jpg # save picture in \static\img\blogs. Acceptable formats= jpg, jpeg, or png . Your iPhone pics wont work

keywords: ""
slug: pre_course # slug is the shorthand URL address... no spaces plz
title: My pre-course assignment
---

```{r load-libraries, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(gapminder)  # gapminder dataset
library(here)
library(janitor)
```

## Task 1: Gapminder country comparison

The `gapminder` dataset has data on life expectancy, population, and GDP per capita for 142 countries from 1952 to 2007. To get a glimpse of the dataframe, namely to see the variable names, variable types, etc., we use the `glimpse` function. We also want to have a look at the first 20 rows of data.

```{r}
glimpse(gapminder)

head(gapminder, 20) # look at the first 20 rows of the dataframe

```

I will produce two graphs of how life expectancy has changed over the years for the `country` and the `continent` I come from.


```{r}
country_data <- gapminder %>% 
            filter(country == "Switzerland")

continent_data <- gapminder %>% 
            filter(continent == "Europe")

plot1 <- ggplot(data = country_data, mapping = aes(x = year, y = lifeExp))+
    geom_point() +
    geom_smooth(se = FALSE) +
    NULL +
    labs(title = "Life expectancy of Switzerland over the years",
          x = "Year",
          y = "Life Expentancy") +
          NULL
plot1

```

Secondly, i will produce a plot for all countries in the *continent* where I come from.

```{r lifeExp_one_continent}
ggplot(continent_data, mapping = aes(x = year, y = lifeExp , colour= country, group = country))+
    geom_point() + 
    geom_smooth(se = FALSE) +
    NULL


```

Finally, I will produce a life expectancy over time graph, grouped (or faceted) by continent.

```{r lifeExp_facet_by_continent}
 ggplot(data = gapminder , mapping = aes(x = year , y = lifeExp , colour= continent))+
   geom_point() + 
   geom_smooth(se = FALSE) +
   facet_wrap(~continent) +
   theme(legend.position="none") +
   NULL
```

Given these trends, what can we say about life expectancy since 1952? In all the continents over time the life expectancy goes up over time. However we can see that it has always been higher in some continets such as Europe and Oceanina.

## Task 2: Brexit vote analysis

We will have a look at the results of the 2016 Brexit vote in the UK. First we read the data using `read_csv()` and have a quick glimpse at the data

```{r load_brexit_data, warning=FALSE, message=FALSE}

# read data directly off github repo
brexit_results <- read_csv("https://raw.githubusercontent.com/kostis-christodoulou/am01/master/data/brexit_results.csv")


glimpse(brexit_results)
```

The data comes from [Elliott Morris](https://www.thecrosstab.com/), who cleaned it and made it available through his [DataCamp class on analysing election and polling data in R](https://www.datacamp.com/courses/analyzing-election-and-polling-data-in-r).

Our main outcome variable (or y) is `leave_share`, which is the percent of votes cast in favour of Brexit, or leaving the EU. Each row is a UK [parliament constituency](https://en.wikipedia.org/wiki/United_Kingdom_Parliament_constituencies).

To get a sense of the spread, or distribution, of the data, we can plot a histogram, a density plot, and the empirical cumulative distribution function of the leave % in all constituencies.

```{r brexit_histogram, warning=FALSE, message=FALSE}

# histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_histogram(binwidth = 2.5) +
    labs(title = "% of Leave share",
          x = "% of leave share",
          y = "Count")

# density plot-- think smoothed histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_density() +
    labs(title = "% of Leave share",
          x = "% of leave share",
          y = "Density")


# The empirical cumulative distribution function (ECDF) 
ggplot(brexit_results, aes(x = leave_share)) +
  stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent) +
    labs(title = "% of Leave share",
          x = "Cumulative % of leave share")
  
```

One common explanation for the Brexit outcome was fear of immigration and opposition to the EU's more open border policy. We can check the relationship (or correlation) between the proportion of native born residents (`born_in_uk`) in a constituency and its `leave_share`. To do this, let us get the correlation between the two variables

```{r brexit_immigration_correlation}
brexit_results %>% 
  select(leave_share, born_in_uk) %>% 
  cor()
```

The correlation is almost 0.5, which shows that the two variables are positively correlated.

We can also create a scatterplot between these two variables.

```{r brexit_immigration_plot}
ggplot(brexit_results, aes(x = born_in_uk, y = leave_share)) +
  geom_point(alpha=0.3) +

  geom_smooth(method = "lm") + 
  
  theme_bw() +
    labs(title = "People born in the Uk and voting for brexit",
          x = "Born in the Uk",
          y = "% of leave share")
  NULL
```


What can we say about the relationship shown above? 

There is a positive correlation between being born in the uk and wanting to leave the EU. Which means that as the share of people born in the uk increases in a consituency the likeliness of them wanting to leave the EU is higher.

There are many more constituencies that have a higher share of people born in the UK. Hence there is more uncertainty around the people not born in the UK.

# Task 4: Animal rescue incidents attended by the London Fire Brigade

[The London Fire Brigade](https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb) attends a range of non-fire incidents (which we call 'special services'). These 'special services' include assistance to animals that may be trapped or in distress. The data is provided from January 2009 and is updated monthly. A range of information is supplied for each incident including some location information (postcode, borough, ward), as well as the data/time of the incidents. We do not routinely record data about animal deaths or injuries.

Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.

```{r load_animal_rescue_data, warning=FALSE, message=FALSE}

url <- "https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/f43b485e-fb35-419c-aa7a-fa75676e5835/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv"


animal_rescue <- read_csv(url,
                          locale = locale(encoding = "CP1252")) %>% 
  janitor::clean_names()


glimpse(animal_rescue)
```
One of the more useful things one can do with any data set is quick counts, namely to see how many observations fall within one category. For instance, if we wanted to count the number of incidents by year, we would either use `group_by()... summarise()` or, simply [`count()`](https://dplyr.tidyverse.org/reference/count.html)

```{r, instances_by_calendar_year}

animal_rescue %>% 
  dplyr::group_by(cal_year) %>% 
  summarise(count=n())

animal_rescue %>% 
  count(cal_year, name="count")

```

Let us try to see how many incidents we have by animal group. Again, we can do this either using group_by() and summarise(), or by using count()

```{r, animal_group_percentages}
animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  summarise(count = n()) %>% 
  mutate(percent = round(100*count/sum(count),2)) %>% 
  arrange(desc(percent))


animal_rescue %>% 
  
  #count does the same thing as group_by and summarise
  # name = "count" will call the column with the counts "count" ( exciting, I know)
  # and 'sort=TRUE' will sort them from max to min
  count(animal_group_parent, name="count", sort=TRUE) %>% 
  mutate(percent = round(100*count/sum(count),2))


```

Let us have a loot at the notional cost for rescuing each of these animals. As the LFB says,

> Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.

There is two things we will do:

1. Calculate the mean and median `incident_notional_cost` for each `animal_group_parent`
2. Plot a boxplot to get a feel for the distribution of `incident_notional_cost` by `animal_group_parent`.


Before we go on, however, we need to fix `incident_notional_cost` as it is stored as a `chr`, or character, rather than a number.

```{r, parse_incident_cost,message=FALSE, warning=FALSE}

# what type is variable incident_notional_cost from dataframe `animal_rescue`
typeof(animal_rescue$incident_notional_cost)

# readr::parse_number() will convert any numerical values stored as characters into numbers
animal_rescue <- animal_rescue %>% 

  # we use mutate() to use the parse_number() function and overwrite the same variable
  mutate(incident_notional_cost = parse_number(incident_notional_cost))

# incident_notional_cost from dataframe `animal_rescue` is now 'double' or numeric
typeof(animal_rescue$incident_notional_cost)

```

Now that incident_notional_cost is numeric, let us quickly calculate summary statistics for each animal group. 


```{r, stats_on_incident_cost,message=FALSE, warning=FALSE}

animal_rescue %>% 
  
  # group by animal_group_parent
  group_by(animal_group_parent) %>% 
  
  # filter resulting data, so each group has at least 6 observations
  filter(n()>6) %>% 
  
  # summarise() will collapse all values into 3 values: the mean, median, and count  
  # we use na.rm=TRUE to make sure we remove any NAs, or cases where we do not have the incident cos
  summarise(mean_incident_cost = mean (incident_notional_cost, na.rm=TRUE),
            median_incident_cost = median (incident_notional_cost, na.rm=TRUE),
            sd_incident_cost = sd (incident_notional_cost, na.rm=TRUE),
            min_incident_cost = min (incident_notional_cost, na.rm=TRUE),
            max_incident_cost = max (incident_notional_cost, na.rm=TRUE),
            count = n()) %>% 
  
  # sort the resulting data in descending order. You choose whether to sort by count or mean cost.
  arrange(desc(mean_incident_cost))

```


As we can see the median and the mean are different in the top 4 groups which may mean we have outliers in those groups. 

Finally, let us plot a few plots that show the distribution of incident_cost for each animal group.

```{r, plots_on_incident_cost_by_animal_group,message=FALSE, warning=FALSE}

# base_plot
base_plot <- animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  filter(n()>6) %>% 
  ggplot(aes(x=incident_notional_cost))+
  facet_wrap(~animal_group_parent, scales = "free")+
  theme_bw()

base_plot + geom_histogram()
base_plot + geom_density()
base_plot + geom_boxplot()
base_plot + stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent)



```

In general the boxplot gives a good idea of the spread. We are also able to identiyf different outliers depening on the shape and the values on used at the bottom of the plots. ie (is it 250 to 300 or 5 to 5000)

It is clear that the horse is the most expensive animal to rescue. It seems to be that the larger the animal the more expensive the rescue.
